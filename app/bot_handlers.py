from aiogram import Bot, F, types, Router
from aiogram.types import FSInputFile
from aiogram.filters import CommandStart, Command
import numpy as np
import imghdr       # –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
#import re
from pathlib import Path
import logging, os 
import pandas as pd
import dataframe_image as dfi
from tabulate import tabulate
from PIL import Image
                                 

import bot_keyboards as kb
import common_utils as utils
import FasterRCNN as faster
import YOLOv12 as yolo
#from app.constants import ARTEFACTS_DIR, CLASS_NAMES
import KerasOCR as kerasocr
import EasyOCR as easyocr
import TrOCR as trocr
import PaddleOCR as paddleocr


router = Router()

async def output_detect_result(message):
    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return

    sent_count = 0
    for image_file, class_name, confidence in image_files:
        try:
            if isinstance(confidence, str):
                confidence = float(confidence)
            elif not isinstance(confidence, (float, int)):
                confidence = 0.0  # –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

            if confidence>0.50:
                caption = (
                    f"üè∑ –ö–ª–∞—Å—Å: {class_name}\n"
                    f"üü¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence}"
                )            
                await message.answer_photo(
                    FSInputFile(image_file),
                    caption=caption
                )
                sent_count += 1
        except Exception as e:
            logging.error(f"Error sending {image_file.name}: {e}")

    await message.answer(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏–∑ {len(image_files)})", reply_markup=kb.ocr)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
def add_ocr_result(df, ocr_system, class_name, recognized_text):
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    col_name = f'text_{ocr_system}'
    if col_name not in df.columns:
        df[col_name] = None
    
    # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    mask = (df['Class'] == class_name)
    if mask.any():
        df.loc[mask, col_name] = recognized_text
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å—Ç—Ä–æ–∫–∏, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é
        new_row = {'Class': class_name, col_name: recognized_text}
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    
    return df

# –°–æ–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –æ–¥–Ω–æ
def combine_images_with_table(table_path, image_data, output_path, padding=10):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–∞–±–ª–∏—Ü—É –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ–¥–Ω–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    
    :param table_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é —Ç–∞–±–ª–∏—Ü—ã (str/Path)
    :param image_data: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (PosixPath, class_name, confidence)
    :param output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (str/Path)
    :param padding: –æ—Ç—Å—Ç—É–ø –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (–ø–∏–∫—Å–µ–ª–∏)
    """
    # 1. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—É—Ç–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    def process_image_data(item):
        path, class_name, confidence = item
        return {
            'path': str(Path(path).absolute()),
            'class': class_name,
            'confidence': float(confidence)
        }
    
    try:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        table_path = str(Path(table_path).absolute())
        output_path = str(Path(output_path).absolute())
        processed_images = [process_image_data(item) for item in image_data]
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        missing = [img['path'] for img in processed_images if not os.path.exists(img['path'])]
        if not os.path.exists(table_path):
            missing.append(table_path)
            
        if missing:
            raise FileNotFoundError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {missing}")
        
        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–¥–ø–∏—Å—è–º–∏
        images = []
        
        # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É
        with Image.open(table_path) as img:
            images.append({
                'image': img.copy(),
                'label': "OCR Results Table"
            })
        
        # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for img_data in processed_images:
            try:
                with Image.open(img_data['path']) as img:
                    label = f"{img_data['class']} (Confidence: {img_data['confidence']:.2f})"
                    images.append({
                        'image': img.copy(),
                        'label': label
                    })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {img_data['path']}: {str(e)}")
                continue
        
        if len(images) <= 1:  # –¢–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—Ü–∞
            raise ValueError("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        max_width = max(img['image'].width for img in images)
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–∏
        def add_caption(base_img, text):
            from PIL import ImageDraw, ImageFont
            font = ImageFont.load_default()
            caption_height = 30
            new_img = Image.new('RGB', 
                              (base_img.width, base_img.height + caption_height),
                              (255, 255, 255))
            new_img.paste(base_img, (0, 0))
            
            draw = ImageDraw.Draw(new_img)
            text_width = draw.textlength(text, font=font)
            draw.text(((base_img.width - text_width) // 2, base_img.height + 5),
                     text, fill="black", font=font)
            return new_img
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–¥–ø–∏—Å—è–º–∏
        processed = []
        for img_data in images:
            img = img_data['image']
            if img.width != max_width:
                new_height = int(img.height * (max_width / img.width))
                img = img.resize((max_width, new_height), Image.LANCZOS)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å
            labeled_img = add_caption(img, img_data['label'])
            processed.append(labeled_img)
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        total_height = sum(img.height for img in processed) + padding * (len(processed)-1)
        combined = Image.new('RGB', (max_width, total_height), (255, 255, 255))
        
        y_offset = 0
        for img in processed:
            combined.paste(img, (0, y_offset))
            y_offset += img.height + padding
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
        combined.save(output_path)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_path}")
        return True
    
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {str(e)}")
        return False


@router.message(CommandStart())
async def cmd_start(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –∫–∞—Ä—Ç—ã.")   #, reply_markup=kb.main


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
@router.message(F.photo)
async def handle_photo(message: types.Message, bot: Bot):
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        file_id = message.photo[-1].file_id  # –ë–µ—Ä–µ–º —Ñ–æ—Ç–æ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
        file = await bot.get_file(file_id)
        file_path = file.file_path
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç—å
        downloaded_file = await bot.download_file(file_path)
        file_bytes = downloaded_file.read()

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_format = imghdr.what(None, h=file_bytes)
        if image_format not in ['jpeg', 'png']:
            await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JPG –∏–ª–∏ PNG")
            return

        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        utils.clean_artefact_dir()
        original_filename = f"artefacts/{file_id}.{image_format}"
        with open(original_filename, "wb") as f:
            f.write(file_bytes)
    
        await message.answer("–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –í—ã–±–µ—Ä–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø–æ–ª–µ–π —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤.", reply_markup=kb.detect)

    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞: {e}")


@router.message(F.text == 'YOLOv12')
async def detect_yolo_v12(message: types.Message, bot: Bot):
    #await message.answer(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø–æ –ø—É—Ç–∏: {img_path}")
    await message.answer("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –¥–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤...")

    try:
        utils.delete_old_detections()
        img_path = utils.get_image_from_artefacts()
        yolo.main(img_path)        
    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        logging.error(f"Detect error: {e}")
    
    await output_detect_result(message)


@router.message(F.text == 'Faster R-CNN')
async def detect_faster_rcnn(message: types.Message, bot: Bot):
    #await message.answer(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø–æ –ø—É—Ç–∏: {img_path}")
    await message.answer("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –¥–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤...")
    
    try:
        utils.delete_old_detections()
        img_path = utils.get_image_from_artefacts()
        faster.main(img_path)        
    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        logging.error(f"Detect error: {e}")

    await output_detect_result(message)


@router.message(F.text == 'KerasOCR')
async def recognition_KerasOCR(message: types.Message, bot: Bot):
    #await message.answer(f"–ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")
    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return

    sent_count = 0
    # try:
    for image_file, class_name, confidence in image_files:
        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ KerasOCR —Ñ–∞–π–ª: {image_file.name}.")
        try:
            full_text, predictions = kerasocr.recognize_with_confidence(image_file)
            print(f"–†–∞–ø–æ–∑–Ω–∞–Ω —Ç–µ–∫—Å—Ç KerasOCR: {full_text}.")
            processed_temp_path = kerasocr.get_tmp_image_file(image_file, predictions)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await message.answer_photo(FSInputFile(processed_temp_path, filename="OCR processed.jpg"))
            #await message.answer(f"{full_text}", reply_markup=kb.ocr)
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            #text_message = "–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n" + "\n".join(texts)
            #await message.answer(text_message)
            os.unlink(processed_temp_path)

            sent_count += 1
        except Exception as e:
            logging.error(f"Error sending {image_file.name}: {e}")

    await message.answer(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏–∑ {len(image_files)})", reply_markup=kb.ocr)
        
    # except Exception as e:
    #     await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    #     logging.error(f"Detect error: {e}")


@router.message(F.text == 'EasyOCR')
async def recognition_EasyOCR(message: types.Message, bot: Bot):
    #await message.answer(f"–ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")
    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return

    sent_count = 0
    # try:
    for image_file, class_name, confidence in image_files:
        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ EasyOCR —Ñ–∞–π–ª: {image_file.name}.")
        try:
            img_path, results, class_id, processed_img = easyocr.recognize_images_in_directory(image_file, languages=['en', 'ru'], gpu=False)

            print("–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            orig_temp_path, processed_temp_path, recognized_texts = utils.prepare_enhanced_results(img_path, results, class_id, processed_img)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await message.answer_photo(FSInputFile(orig_temp_path, filename="detected region.jpg"))
            await message.answer_photo(FSInputFile(processed_temp_path, filename="OCR processed.jpg"))
            await message.answer(f"{recognized_texts}", reply_markup=kb.ocr)
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            #text_message = "–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n" + "\n".join(texts)
            #await message.answer(text_message)
            os.unlink(orig_temp_path)
            os.unlink(processed_temp_path)

            sent_count += 1
        except Exception as e:
            logging.error(f"Error sending {image_file.name}: {e}")

    await message.answer(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏–∑ {len(image_files)})", reply_markup=kb.ocr)
        
    # except Exception as e:
    #     await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    #     logging.error(f"Detect error: {e}")


@router.message(F.text == 'TrOCR')
async def recognition_TrOCR(message: types.Message, bot: Bot):

    #await message.answer(f"–ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")
    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return

    sent_count = 0
    # try:
    for image_file, class_name, confidence in image_files:
        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ KerasOCR —Ñ–∞–π–ª: {image_file.name}.")
        try:
            #img_path, results, class_id, processed_img = trocr.recognize_images_in_directory(image_file, languages=['en', 'ru'], gpu=False)
            outputs, processor = trocr.recognize_images_in_directory(image_file)
            full_text, confidences = trocr.get_text_with_confidence(outputs, processor)

            print("–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            await message.answer(f"\'{full_text}\' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidences:.3f})")
            # orig_temp_path, processed_temp_path, recognized_texts = utils.prepare_enhanced_results(img_path, results, class_id, processed_img)

            # # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            # await message.answer_photo(FSInputFile(orig_temp_path, filename="detected region.jpg"))
            # await message.answer_photo(FSInputFile(processed_temp_path, filename="OCR processed.jpg"))
            # await message.answer(f"{recognized_texts}", reply_markup=kb.ocr)
            # # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            # #text_message = "–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n" + "\n".join(texts)
            # #await message.answer(text_message)
            # os.unlink(orig_temp_path)
            # os.unlink(processed_temp_path)

            sent_count += 1
        except Exception as e:
            logging.error(f"Error sending {image_file.name}: {e}")

    await message.answer(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏–∑ {len(image_files)})", reply_markup=kb.ocr)
        
    # except Exception as e:
    #     await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    #     logging.error(f"Detect error: {e}")

@router.message(F.text == 'PaddleOCR')
async def recognition_PaddleOCR(message: types.Message, bot: Bot):

    #await message.answer(f"–ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")
    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return

    sent_count = 0
    # try:
    for image_file, class_name, confidence in image_files:
        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ KerasOCR —Ñ–∞–π–ª: {image_file.name}.")
        try:
            #img_path, results, class_id, processed_img = trocr.recognize_images_in_directory(image_file, languages=['en', 'ru'], gpu=False)
            full_text, confidences = paddleocr.recognize_images_in_directory(image_file)

            print("–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            await message.answer(f"\'{full_text}\' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidences:.3f})")
            # orig_temp_path, processed_temp_path, recognized_texts = utils.prepare_enhanced_results(img_path, results, class_id, processed_img)

            # # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            # await message.answer_photo(FSInputFile(orig_temp_path, filename="detected region.jpg"))
            # await message.answer_photo(FSInputFile(processed_temp_path, filename="OCR processed.jpg"))
            # await message.answer(f"{recognized_texts}", reply_markup=kb.ocr)
            # # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            # #text_message = "–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n" + "\n".join(texts)
            # #await message.answer(text_message)
            # os.unlink(orig_temp_path)
            # os.unlink(processed_temp_path)

            sent_count += 1
        except Exception as e:
            logging.error(f"Error sending {image_file.name}: {e}")

    await message.answer(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏–∑ {len(image_files)})", reply_markup=kb.ocr)
        
    # except Exception as e:
    #     await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    #     logging.error(f"Detect error: {e}")


@router.message(F.text == 'TrOCR + PaddleOCR')
async def ensemble_OCR(message: types.Message, bot: Bot):
    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return

    sent_count = 0
    # try:
    for image_file, class_name, confidence in image_files:
        try:
            if class_name == 'DateExpired':
                outputs, processor = trocr.recognize_images_in_directory(image_file)
                full_text, confidences = trocr.get_text_with_confidence(outputs, processor)

                print("–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                await message.answer(f"\'{full_text}\' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidences:.3f})")
            else:
                full_text, confidences = paddleocr.recognize_images_in_directory(image_file)

                print("–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                await message.answer(f"\'{full_text}\' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidences:.3f})")

            sent_count += 1

        except Exception as e:
            logging.error(f"Error sending {image_file.name}: {e}")

    await message.answer(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {sent_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏–∑ {len(image_files)})", reply_markup=kb.ocr)


@router.message(F.text == '–°—Ä–∞–≤–Ω–∏—Ç—å OCR')
async def compare_OCR(message: types.Message, bot: Bot):
    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    columns = [
        'Class'      # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–µ –ø–æ–ª–µ
    ]
    df = pd.DataFrame(columns=columns)

    image_files = utils.get_list_of_images()

    if not image_files:
        logging.error(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–º–µ–Ω–∏.")
        return
    
    for image_file, class_name, confidence in image_files:
        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ KerasOCR —Ñ–∞–π–ª: {image_file}.")
        await message.answer(f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –∏–¥–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ KerasOCR –∫–ª–∞—Å—Å–∞: {class_name}", reply_markup=kb.ocr)
        try:
            full_text, predictions = kerasocr.recognize_with_confidence(image_file)
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'KerasOCR', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file}: {e}")

        # logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ EasyOCR —Ñ–∞–π–ª: {image_file.name}.")
        await message.answer(f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –∏–¥–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ EasyOCR –∫–ª–∞—Å—Å–∞: {class_name}", reply_markup=kb.ocr)
        try:
            img_path, results, class_id, processed_img = easyocr.recognize_images_in_directory(image_file, languages=['en', 'ru'], gpu=False)
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_text = []
            for i, (_, text, prob) in enumerate(results):
                #print(f"{i+1}. {text} (—Ç–æ—á–Ω–æ—Å—Ç—å: {prob:.2f})")
                result_text.append(text)
            full_text = ''.join(result_text)
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'EasyOCR', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file.name}: {e}")

        # logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ TrOCR —Ñ–∞–π–ª: {image_file.name}.")
        await message.answer(f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –∏–¥–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ TrOCR –∫–ª–∞—Å—Å–∞: {class_name}", reply_markup=kb.ocr)
        try:
            outputs, processor = trocr.recognize_images_in_directory(image_file)
            full_text, confidences = trocr.get_text_with_confidence(outputs, processor)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'TrOCR', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file.name}: {e}")

        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ PaddleOCR —Ñ–∞–π–ª: {image_file.name}.")
        await message.answer(f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –∏–¥–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ PaddleOCR –∫–ª–∞—Å—Å–∞: {class_name}", reply_markup=kb.ocr)       
        try:
            full_text, confidences = paddleocr.recognize_images_in_directory(image_file)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'PaddleOCR', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file.name}: {e}")

     
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'TrOCR', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file.name}: {e}")   #         # logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ TrOCR —Ñ–∞–π–ª: {image_file.name}.")
        try:
            outputs, processor = trocr.recognize_images_in_directory(image_file)
            full_text, confidences = trocr.get_text_with_confidence(outputs, processor)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'TrOCR', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file.name}: {e}")

        #logging.INFO(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ –∞–Ω—Å–∞–º–±–ª—å —Ñ–∞–π–ª: {image_file.name}.")
        await message.answer(f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –∏–¥–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ 'PaddleOCR + TrOCR' –∫–ª–∞—Å—Å–∞: {class_name}", reply_markup=kb.ocr)    
        try:
            if class_name == 'CardNumber':
                full_text, confidences = paddleocr.recognize_images_in_directory(image_file)
            else:
                outputs, processor = trocr.recognize_images_in_directory(image_file)
                full_text, confidences = trocr.get_text_with_confidence(outputs, processor)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            df = add_ocr_result(df, 'Ansible', class_name, full_text)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {image_file.name}: {e}")

    print(tabulate(df, headers='keys', tablefmt='fancy_grid', showindex=False))

    table_image = "ocr_results_table.png"
    output_file = "combined_result.png"
    dfi.export(df, table_image, table_conversion='matplotlib')
    combine_images_with_table(table_image, image_files, output_file, padding=20)

    await message.answer_photo(FSInputFile(output_file, filename="OCR processed.jpg"))

