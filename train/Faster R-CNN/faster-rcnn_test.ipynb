{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fc2ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5179ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация\n",
    "# MODEL_PATH = '/home/lastinm/PROJECTS/credit_cards_detection/train/Faster R-CNN/exp/summary/02-05-2025-15-46-48/best_model.pth'\n",
    "MODEL_PATH = '/home/lastinm/PROJECTS/credit_cards_detection/train/Faster R-CNN/exp/summary/19-05-2025-20-54-34/best_model.pth'\n",
    "TEST_DATA_DIR = '/home/lastinm/PROJECTS/credit_cards_detection/dataset/coco/test/images'\n",
    "ANNOTATIONS_FILE = '/home/lastinm/PROJECTS/credit_cards_detection/dataset/coco/test/_annotations.coco.json'  # COCO format\n",
    "RESULTS_DIR = 'results'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #'cpu' #\n",
    "NUM_CLASSES = 4  # Фон + ваш класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80ab30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, image, target):\n",
    "        return F.to_tensor(image), target\n",
    "\n",
    "def get_transform():\n",
    "    return Compose([\n",
    "        ToTensor(),  # Конвертирует PIL Image в тензор\n",
    "        # Здесь можно добавить другие преобразования\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ff67b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "    # Загрузка модели с правильной архитектурой\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "    \n",
    "    # Загрузка весов\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "        \n",
    "        # Проверка наличия model_state_dict\n",
    "        if 'model_state_dict' not in checkpoint:\n",
    "            raise KeyError(\"Checkpoint does not contain 'model_state_dict'\")\n",
    "        \n",
    "        # Загрузка весов\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Файл модели не найден: {MODEL_PATH}\")\n",
    "    \n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0be3c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_faster_rcnn():\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    \n",
    "    # 1. Загрузка модели\n",
    "    model = load_model()\n",
    "    model.eval()\n",
    "    \n",
    "    # 2. Загрузка тестовых данных с правильными преобразованиями\n",
    "    transform = get_transform()  # Используем наш преобразователь\n",
    "    \n",
    "    dataset = torchvision.datasets.CocoDetection(\n",
    "        TEST_DATA_DIR,\n",
    "        ANNOTATIONS_FILE,\n",
    "        transforms=transform  # Передаём правильные transforms\n",
    "    )\n",
    "    \n",
    "    # 3. Метрики\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        image, target = dataset[idx]\n",
    "        image = image.to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            prediction = model([image])[0]\n",
    "        \n",
    "        # Визуализация\n",
    "        plot_results(image, prediction, target, idx)\n",
    "        \n",
    "        # Сохранение для расчета метрик\n",
    "        all_preds.append(prediction)\n",
    "        all_targets.append(target)\n",
    "    \n",
    "    # 4. Расчет метрик\n",
    "    calculate_metrics(all_preds, all_targets)\n",
    "\n",
    "\n",
    "def plot_results(image, prediction, target, idx):\n",
    "    \"\"\"Визуализация результатов детекции\"\"\"\n",
    "    # Конвертируем тензор обратно в numpy для отображения\n",
    "    image = image.cpu().permute(1, 2, 0).numpy()\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Отрисовка GT (Ground Truth)\n",
    "    for ann in target:  # target - это список аннотаций COCO\n",
    "        box = ann['bbox']  # COCO использует формат [x,y,width,height]\n",
    "        # Конвертируем в формат [x1,y1,x2,y2]\n",
    "        box = [box[0], box[1], box[0]+box[2], box[1]+box[3]]\n",
    "        rect = plt.Rectangle(\n",
    "            (box[0], box[1]),\n",
    "            box[2] - box[0],\n",
    "            box[3] - box[1],\n",
    "            fill=False,\n",
    "            color='green',\n",
    "            linewidth=2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # Отрисовка предсказаний\n",
    "    for box, score in zip(prediction['boxes'], prediction['scores']):\n",
    "        if score > 0.5:  # Порог уверенности\n",
    "            box = box.cpu().numpy()  # Конвертируем тензор в numpy\n",
    "            rect = plt.Rectangle(\n",
    "                (box[0], box[1]),\n",
    "                box[2] - box[0],\n",
    "                box[3] - box[1],\n",
    "                fill=False,\n",
    "                color='red',\n",
    "                linewidth=2\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(\n",
    "                box[0], box[1],\n",
    "                f'{score:.2f}',\n",
    "                color='white',\n",
    "                bbox=dict(facecolor='red', alpha=0.5)\n",
    "            )\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.savefig(\n",
    "        os.path.join(RESULTS_DIR, f'result_{idx}.png'),\n",
    "        bbox_inches='tight',\n",
    "        pad_inches=0\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd2ca8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, targets):\n",
    "    \"\"\"Расчет mAP и Precision\"\"\"\n",
    "    # Преобразование в COCO формат\n",
    "    coco_results = []\n",
    "    all_pred_labels = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    for img_id, (pred, target) in enumerate(zip(predictions, targets)):\n",
    "        # Для Precision: собираем предсказанные и истинные классы\n",
    "        pred_labels = pred['labels'].cpu().numpy()\n",
    "        true_labels = [ann['category_id'] for ann in target]\n",
    "        \n",
    "        # Для COCO метрик\n",
    "        for box, score, label in zip(pred['boxes'], pred['scores'], pred['labels']):\n",
    "            coco_results.append({\n",
    "                'image_id': img_id,\n",
    "                'category_id': label.item(),\n",
    "                'bbox': [box[0].item(), box[1].item(), \n",
    "                        (box[2]-box[0]).item(), (box[3]-box[1]).item()],\n",
    "                'score': score.item()\n",
    "            })\n",
    "        \n",
    "        # Для Precision (нужно согласовать количество предсказаний и GT)\n",
    "        # Здесь простой вариант - сравниваем основные предсказания\n",
    "        if len(pred_labels) > 0 and len(true_labels) > 0:\n",
    "            all_pred_labels.append(pred_labels[0])  # Берем самый уверенный bbox\n",
    "            all_true_labels.append(true_labels[0])   # Берем первый GT bbox\n",
    "    \n",
    "    # Расчет Precision\n",
    "    if len(all_pred_labels) > 0 and len(all_true_labels) > 0:\n",
    "        precision = precision_score(\n",
    "            all_true_labels,\n",
    "            all_pred_labels,\n",
    "            average='macro',  # Можно использовать 'micro' или 'binary' для одного класса\n",
    "            zero_division=0\n",
    "        )\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    # Инициализация COCO API\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "    \n",
    "    coco_gt = COCO(ANNOTATIONS_FILE)\n",
    "    coco_dt = coco_gt.loadRes(coco_results)\n",
    "    \n",
    "    # Оценка COCO\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    \n",
    "    # Сохранение метрик\n",
    "    metrics = {\n",
    "        'mAP@0.5:0.95': coco_eval.stats[0],\n",
    "        'mAP@0.5': coco_eval.stats[1],\n",
    "        'mAP@0.75': coco_eval.stats[2],\n",
    "        'Recall@0.5': coco_eval.stats[8],\n",
    "        'Precision': precision  # Добавляем Precision\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(RESULTS_DIR, 'metrics.txt'), 'w') as f:\n",
    "        for k, v in metrics.items():\n",
    "            f.write(f\"{k}: {v:.4f}\\n\")\n",
    "            print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3af9ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.797\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.883\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.712\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.876\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.821\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.827\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.827\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.742\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.911\n",
      "mAP@0.5:0.95: 0.7967\n",
      "mAP@0.5: 0.8927\n",
      "mAP@0.75: 0.8832\n",
      "Recall@0.5: 0.8272\n",
      "Precision: 0.3333\n"
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "evaluate_faster_rcnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
