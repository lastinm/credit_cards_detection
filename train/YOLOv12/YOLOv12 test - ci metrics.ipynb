{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be415d7e",
   "metadata": {},
   "source": [
    "–î–æ–±–∞–≤–ª–µ–Ω –±—É—Ç—Å—Ç—Ä–∞–ø-–∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤:\n",
    "- –î–ª—è precision –∏ recall –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±—É—Ç—Å—Ç—Ä–∞–ø –ø–æ –∫–ª–∞—Å—Å–∞–º\n",
    "- –î–ª—è mAP –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ (—Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ —Å–∫–∞–ª—è—Ä–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)\n",
    "\n",
    "–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–æ–≤:\n",
    "- –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 1000 –∏—Ç–µ—Ä–∞—Ü–∏–π –±—É—Ç—Å—Ç—Ä–∞–ø–∞ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏\n",
    "\n",
    "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n",
    "- –ú–µ—Ç—Ä–∏–∫–∏ —Å CI —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Ñ–∞–π–ª metrics.txt\n",
    "\n",
    "–î–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n",
    "- –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω, –≤ –∫–æ—Ç–æ—Ä–æ–º —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 95% –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "- –£–∑–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω—É—é –æ—Ü–µ–Ω–∫—É\n",
    "- –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è, —Ä–∞–∑–ª–∏—á–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1bd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847774ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "MODEL_PATH = '/home/lastinm/PROJECTS/credit_cards_detection/train/YOLOv12/runs/detect/train2/weights/best.pt'  # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏\n",
    "TEST_DATA_DIR = '/home/lastinm/PROJECTS/credit_cards_detection/dataset/yolo/test/images'  # –ü–∞–ø–∫–∞ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n",
    "DATASET_YAML = '/home/lastinm/PROJECTS/credit_cards_detection/dataset/yolo/data.yaml'\n",
    "RESULTS_DIR = 'results'  # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "CONF_THRESH = 0.5  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏\n",
    "IOU_THRESH = 0.5  # –ü–æ—Ä–æ–≥ IoU –¥–ª—è NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9050c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.141 üöÄ Python-3.11.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070, 11875MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 206.3¬±32.5 MB/s, size: 126.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/lastinm/PROJECTS/credit_cards_detection/dataset/yolo/valid/labels.cache... 50 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        140      0.998      0.987       0.99      0.929\n",
      "            CardHolder         41         41          1          1      0.995      0.912\n",
      "            CardNumber         50         50      0.993       0.96      0.979      0.946\n",
      "           DateExpired         49         49          1          1      0.995       0.93\n",
      "Speed: 1.1ms preprocess, 4.6ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1m/home/lastinm/PROJECTS/credit_cards_detection/runs/detect/val\u001b[0m\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏ (95%):\n",
      "mAP@0.5: 0.9292 [0.9096, 0.9488]\n",
      "mAP@0.5-0.95: 0.9898 [0.9702, 1.0094]\n",
      "Precision: 0.9976 [0.9929, 1.0000]\n",
      "Recall: 0.9867 [0.9600, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_yolov12():\n",
    "    # 1. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    \n",
    "    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not os.path.exists(TEST_DATA_DIR):\n",
    "        raise FileNotFoundError(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {TEST_DATA_DIR}\")\n",
    "    \n",
    "    # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL_PATH}\")\n",
    "    \n",
    "    model = YOLO(MODEL_PATH)\n",
    "    \n",
    "    # 4. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "    test_images = [os.path.join(TEST_DATA_DIR, f) for f in os.listdir(TEST_DATA_DIR) \n",
    "                  if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    if not test_images:\n",
    "        raise ValueError(f\"–í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {TEST_DATA_DIR} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (.jpg/.png)\")\n",
    "    \n",
    "    # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "    for img_path in test_images:\n",
    "        try:\n",
    "            pred = model.predict(img_path, conf=CONF_THRESH, iou=IOU_THRESH, verbose=False)\n",
    "            if pred and len(pred) > 0:\n",
    "                pred_img = pred[0].plot()\n",
    "                output_path = os.path.join(RESULTS_DIR, os.path.basename(img_path))\n",
    "                Image.fromarray(pred_img[..., ::-1]).save(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {img_path}: {str(e)}\")\n",
    "    \n",
    "    # 6. –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏\n",
    "    if os.path.exists(DATASET_YAML):\n",
    "        # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "        metrics = model.val(\n",
    "            data=DATASET_YAML,\n",
    "            batch=8,\n",
    "            imgsz=640,\n",
    "            conf=CONF_THRESH,\n",
    "            iou=IOU_THRESH,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        \n",
    "        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—É—Ç—Å—Ç—Ä–∞–ø-–∞–Ω–∞–ª–∏–∑–∞\n",
    "        def bootstrap_metric(metric_values, n_iterations=1000):\n",
    "            bootstrapped = []\n",
    "            for _ in range(n_iterations):\n",
    "                sample = resample(metric_values, replace=True)\n",
    "                bootstrapped.append(np.mean(sample))\n",
    "            return np.percentile(bootstrapped, [2.5, 97.5])\n",
    "        \n",
    "        # –†–∞—Å—á–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤\n",
    "        def calculate_ci(metric_value, metric_values=None, n_iterations=1000):\n",
    "            if metric_values is not None:\n",
    "                ci = bootstrap_metric(metric_values, n_iterations)\n",
    "            else:\n",
    "                # –î–ª—è —Å–∫–∞–ª—è—Ä–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ\n",
    "                ci = stats.norm.interval(0.95, loc=metric_value, scale=0.01)  # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "            return ci\n",
    "        \n",
    "        # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏\n",
    "        metrics_dict = {\n",
    "            \"mAP@0.5\": metrics.box.map,\n",
    "            \"mAP@0.5-0.95\": metrics.box.map75,\n",
    "            \"Precision\": np.mean(metrics.box.p) if hasattr(metrics.box, 'p') else None,\n",
    "            \"Recall\": np.mean(metrics.box.r) if hasattr(metrics.box, 'r') else None\n",
    "        }\n",
    "        \n",
    "        # –†–∞—Å—á–µ—Ç CI –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "        metrics_with_ci = {}\n",
    "        for name, value in metrics_dict.items():\n",
    "            if value is not None:\n",
    "                if name in [\"Precision\", \"Recall\"]:\n",
    "                    # –î–ª—è precision –∏ recall –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—É—Ç—Å—Ç—Ä–∞–ø –ø–æ –∫–ª–∞—Å—Å–∞–º\n",
    "                    metric_values = metrics.box.p if name == \"Precision\" else metrics.box.r\n",
    "                    ci = calculate_ci(value, metric_values)\n",
    "                else:\n",
    "                    # –î–ª—è mAP –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ\n",
    "                    ci = calculate_ci(value)\n",
    "                \n",
    "                metrics_with_ci[name] = {\n",
    "                    \"value\": value,\n",
    "                    \"ci_lower\": ci[0],\n",
    "                    \"ci_upper\": ci[1]\n",
    "                }\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        print(\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏ (95%):\")\n",
    "        for name, data in metrics_with_ci.items():\n",
    "            print(f\"{name}: {data['value']:.4f} [{data['ci_lower']:.4f}, {data['ci_upper']:.4f}]\")\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫—Ä–∏–≤—ã—Ö\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i, (precision, recall) in enumerate(zip(metrics.box.p, metrics.box.r)):\n",
    "            plt.plot(recall, precision, label=f'Class {i} ({model.names[i]})')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(RESULTS_DIR, 'PR_curve.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Å CI\n",
    "        with open(os.path.join(RESULTS_DIR, 'metrics.txt'), 'w') as f:\n",
    "            for name, data in metrics_with_ci.items():\n",
    "                f.write(f\"{name}: {data['value']:.4f} [{data['ci_lower']:.4f}, {data['ci_upper']:.4f}]\\n\")\n",
    "    else:\n",
    "        print(f\"–§–∞–π–ª {DATASET_YAML} –Ω–µ –Ω–∞–π–¥–µ–Ω. –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "evaluate_yolov12()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cuda118_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
